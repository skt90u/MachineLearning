library(corrplot)
# nnet: 拟合单个潜层级的神经网络模型
library(nnet)
# car: 回归模型解释和可视化工具，其它附加功能； 其中包括some()和scatterplotMatrix()函数
library(car)
# gpairs: 广义散点图；对混合类别和连续变量产生散点图矩阵
library(gpairs)
# reshape2: 灵活重构和整合数据，主要有两个函数melt()和dcast()
library(reshape2)
# psych: 心理计量学方法和抽样调查分析，尤其是因子分析和项目反应模型；
# 我们会使用包中的describe()函数
library(psych)
# plyr: 可以将数据分割成更小的数据，然后对分割后的数据进行些操作，最后把操作的结果汇总
library(plyr)
library(caret)
# e1071: 各类计量经济和机器学习的延伸；我们通过naiveBayes()函数进行朴素贝叶斯判别
library(e1071)
# gridExtra: 绘图辅助功能，将不同的图形组合在一起成为图表
library(gridExtra)
# lattice: 建立在核心绘图能力上的格子框架图形
library(lattice)
library(ggplot2)
# imputeMissings: 填补缺失值
library(imputeMissings)
# RANN: 应用k邻近算法
library(RANN)
# corrplot: 相关矩阵的高级可视化
library(corrplot)
# nnet: 拟合单个潜层级的神经网络模型
library(nnet)
# car: 回归模型解释和可视化工具，其它附加功能； 其中包括some()和scatterplotMatrix()函数
library(car)
# gpairs: 广义散点图；对混合类别和连续变量产生散点图矩阵
library(gpairs)
# reshape2: 灵活重构和整合数据，主要有两个函数melt()和dcast()
library(reshape2)
# psych: 心理计量学方法和抽样调查分析，尤其是因子分析和项目反应模型；
# 我们会使用包中的describe()函数
library(psych)
# plyr: 可以将数据分割成更小的数据，然后对分割后的数据进行些操作，最后把操作的结果汇总
library(plyr)
library(caret)
# e1071: 各类计量经济和机器学习的延伸；我们通过naiveBayes()函数进行朴素贝叶斯判别
library(e1071)
# gridExtra: 绘图辅助功能，将不同的图形组合在一起成为图表
library(gridExtra)
# lattice: 建立在核心绘图能力上的格子框架图形
library(lattice)
library(ggplot2)
# imputeMissings: 填补缺失值
library(imputeMissings)
# RANN: 应用k邻近算法
library(RANN)
# corrplot: 相关矩阵的高级可视化
library(corrplot)
# nnet: 拟合单个潜层级的神经网络模型
library(nnet)
# car: 回归模型解释和可视化工具，其它附加功能； 其中包括some()和scatterplotMatrix()函数
library(car)
# gpairs: 广义散点图；对混合类别和连续变量产生散点图矩阵
library(gpairs)
# reshape2: 灵活重构和整合数据，主要有两个函数melt()和dcast()
library(reshape2)
# psych: 心理计量学方法和抽样调查分析，尤其是因子分析和项目反应模型；
# 我们会使用包中的describe()函数
library(psych)
# plyr: 可以将数据分割成更小的数据，然后对分割后的数据进行些操作，最后把操作的结果汇总
library(plyr)
library(caret)
# e1071: 各类计量经济和机器学习的延伸；我们通过naiveBayes()函数进行朴素贝叶斯判别
library(e1071)
# gridExtra: 绘图辅助功能，将不同的图形组合在一起成为图表
library(gridExtra)
# lattice: 建立在核心绘图能力上的格子框架图形
library(lattice)
library(ggplot2)
# imputeMissings: 填补缺失值
library(imputeMissings)
# RANN: 应用k邻近算法
library(RANN)
# corrplot: 相关矩阵的高级可视化
library(corrplot)
# nnet: 拟合单个潜层级的神经网络模型
library(nnet)
# car: 回归模型解释和可视化工具，其它附加功能； 其中包括some()和scatterplotMatrix()函数
library(car)
# gpairs: 广义散点图；对混合类别和连续变量产生散点图矩阵
library(gpairs)
# reshape2: 灵活重构和整合数据，主要有两个函数melt()和dcast()
library(reshape2)
# psych: 心理计量学方法和抽样调查分析，尤其是因子分析和项目反应模型；
# 我们会使用包中的describe()函数
library(psych)
# plyr: 可以将数据分割成更小的数据，然后对分割后的数据进行些操作，最后把操作的结果汇总
library(plyr)
library(caret)
# e1071: 各类计量经济和机器学习的延伸；我们通过naiveBayes()函数进行朴素贝叶斯判别
library(e1071)
# gridExtra: 绘图辅助功能，将不同的图形组合在一起成为图表
library(gridExtra)
# lattice: 建立在核心绘图能力上的格子框架图形
library(lattice)
library(ggplot2)
# imputeMissings: 填补缺失值
library(imputeMissings)
# RANN: 应用k邻近算法
library(RANN)
# corrplot: 相关矩阵的高级可视化
library(corrplot)
# nnet: 拟合单个潜层级的神经网络模型
library(nnet)
# car: 回归模型解释和可视化工具，其它附加功能； 其中包括some()和scatterplotMatrix()函数
library(car)
# gpairs: 广义散点图；对混合类别和连续变量产生散点图矩阵
library(gpairs)
# reshape2: 灵活重构和整合数据，主要有两个函数melt()和dcast()
library(reshape2)
# psych: 心理计量学方法和抽样调查分析，尤其是因子分析和项目反应模型；
# 我们会使用包中的describe()函数
library(psych)
# plyr: 可以将数据分割成更小的数据，然后对分割后的数据进行些操作，最后把操作的结果汇总
library(plyr)
sim.dat<-read.csv("https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv")
rm('aaa')
View(sim.dat)
str(sim.dat)
View(sim.dat)
summary(sim.dat)
sim.dat$age[which(sim.dat$age>100)]
sim.dat$age[which(sim.dat$age>100)]<-NA
sim.dat$age[which(sim.dat$age>100)]
sim.dat$store_exp[which(sim.dat$store_exp<0)]
install.packages("caret")
install.packages("e1071")
install.packages("gridExtra")
install.packages("lattice")
install.packages("imputeMissings")
install.packages("RANN")
install.packages("corrplot")
install.packages("nnet")
install.packages("car")
install.packages("gpairs")
install.packages("reshape2")
install.packages("psych")
sim.dat$age[which(sim.dat$age>100)]<-NA
sim.dat$age[which(sim.dat$age>100)]<-NA
source('~/Downloads/Rcode.R', echo=TRUE)
preProcess
loadings()
?str
?sd
age <- c(1,3,5,2,11,9,12,3)
history()
history(#)
q
alb
a
a
str.libPaths
mean.libPaths
library(plyr)
search()
installed.packages()
c("age","income")
a <- c(1,2,3)
b <- c('1', '2', '3')
a[1]
a[1] <- '1'
a[1] <- 1
a
a <- c(1,2,3)
a
a[1] <- '1'
a
c <- list(1,2,3)
c
c[1][1]
c[2][1]
c[3][1]
c[1][2] <- 2
summary
a <- c(11,22,33,44,55)
a[c(2,3)]
a[2,3]
a[2:3]
a[2:5]
a[2:15]
a[-2:15]
a[-2]
a
a[-1]
a[-3]
a[-4]
rm(list=ls())
cat('\f')
lst = c(1,2,3)
lst[1]
lst[1] = FALSE
lst
lst[1] = 'cc'
lst
c
vector
c
d <- seq(1,9)
d
m <- matrix(d, nrow = 3, ncol = 3)
m
m <- matrix(d, nrow = 1, ncol = 3)
m
m <- matrix(d, nrow = 1, ncol = 9)
m
q <- 1:20
q
q
q[1]
q[1] <- TRUE
TRUE
q
q[1] <- FALSE
q
edit()
a <- c(1,2,3)
edit(a)
fix(a)
a
fix
?str
sim.dat<-read.csv("https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv")
rm(list=ls())
sim.dat<-read.csv("https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv")
str(sim.dat)
sim.dat$age
str(sim.dat$age)
class(sim.dat$age)
summary(sim.dat$age)
sim.dat$age[which(sim.dat$age>100)]
sim.dat$age[which(sim.dat$age<0)]
sim.dat$store_exp[which(sim.dat$satore_exp<0)]
rm(list=ls())
sim.dat<-read.csv("https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv")
hist(sim.dat$age)
sim.dat$age[which(sim.dat$age>100)]<-NA
hist(sim.dat$age)
par(mar = rep(2, 4))
hist(sim.dat$age)
subset
?subset
predict
?preProcess
library(caret)
library(e1071)
library(gridExtra)
library(lattice)
library(ggplot2)
library(imputeMissings)
library(RANN)
library(corrplot)
library(nnet)
library(car)
library(gpairs)
library(reshape2)
library(psych)
library(plyr)
sim.dat<-read.csv("https://raw.githubusercontent.com/happyrabbit/DataScientistR/master/Data/SegData.csv")
str(sim.dat)
summary(sim.dat)
sim.dat$age[which(sim.dat$age>100)]<-NA
sim.dat$store_exp[which(sim.dat$satore_exp<0)]<-NA
summary(subset(sim.dat,select=c("age","income")))
demo_imp<-impute(sim.dat,method="median/mode")
impute
?impute
cat('\f')
c(630,640,640,640,650)
dat1 <- c(630,640,640,640,650)
dat2 <- c(6.3,6.4,6.4,6.4,6.5)
mean(dat1)
mean(dat2)
sd(dat1)
sd(dat2)
sd(dat2)/(length(dat1)-1)
sd(dat1)/(length(dat1)-1)
sd(dat2)/(length(dat2)-1)
sd(dat2)/mean(dat2)
sd(dat1)/mean(dat1)
library(readr)
Salary_Data <- read_csv("~/Desktop/Machine Learning A-Z/Part 2 - Regression/Section 4 - Simple Linear Regression/Salary_Data.csv")
View(Salary_Data)
View(Salary_Data)
View(Salary_Data)
View(Salary_Data)
View(Salary_Data)
View(Salary_Data)
rm(list=ls())
dataset = read.csv('Salary_Data.csv')
dataset = read.csv('Salary_Data.csv')
setwd("~/Desktop/Machine Learning A-Z/Part 2 - Regression/Section 4 - Simple Linear Regression")
dataset = read.csv('Salary_Data.csv')
View(dataset)
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
View(test_set)
View(training_set)
regressor = lm(formula = Salary ~ YearsExperience,
data = training_set)
summary(regressor)
ls <- c(1,2,3,2,1)
mean(ls)
ls <- c(1,2,3,3,2,1)
mean(ls)
sd(ls)
len(ls)
length(ls)
sd(ls)
(1 + 4 + 9 + 9 + 4 + 1 - 4)
sd(ls) * 5
mean(ls)
View(test_set)
rm(list = ls())
MEAN <- mean(ls)
ls <- c(1,2,3,3,2,1)
MEAN <- mean(ls)
SD <- sd(ls)
SD * 25
sqrt(0.8)
var(ls)
is.data.frame(ls)
(1 + 4 + 9 + 9 + 4 + 1)/5
5.6 - 4
28 - 4
(28 - 4)/5
(1 + 4 + 9 + 9 + 4 + 1)/6
(1 + 4 + 9 + 9 + 4 + 1)/5
(1 + 4 + 9 + 9 + 4 + 1)/5 -4
(1 + 4 + 9 + 9 + 4 + 1)/6 -4
sqrt((1 + 4 + 9 + 9 + 4 + 1)/6 -4)
ls <- c(1,2,3,3,2,1)
MEAN <- mean(ls)
SD <- sd(ls)
VAR <- var(ls)
sqar(VAR)
sqrt(VAR)
(28/5)
28/6
missing(use)
na.method
C_cov
y_pred = predict(regressor, newdata = test_set)
dataset = read.csv('Salary_Data.csv')
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
#library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
# training_set = scale(training_set)
# test_set = scale(test_set)
# Fitting Simple Linear Regression to the Training set
# Salary ~ YearsExperience stand for the Salary is proportional to YearsExperience
regressor = lm(formula = Salary ~ YearsExperience,
data = training_set)
# Predicting the Test set results
y_pred = predict(regressor, newdata = test_set)
rm(list=ls())
# Simple Linear Regression
# Importing the dataset
dataset = read.csv('Salary_Data.csv')
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
#library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
# training_set = scale(training_set)
# test_set = scale(test_set)
# Fitting Simple Linear Regression to the Training set
# Salary ~ YearsExperience stand for the Salary is proportional to YearsExperience
regressor = lm(formula = Salary ~ YearsExperience,
data = training_set)
# Predicting the Test set results
y_pred = predict(regressor, newdata = test_set)
library(ggplot2)
library(ggplot2)
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
# Visualising the Test set results
library(ggplot2)
ggplot() +
geom_point(aes(x = test_set$YearsExperience, y = test_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Experience (Test set)') +
xlab('Years of experience') +
ylab('Salary')
ggplot()
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red')
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue')
ggtitle('Salary vs Experience (Training set)')
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
library(ggplot2)
ggplot() +
geom_point(aes(x = test_set$YearsExperience, y = test_set$Salary),
colour = 'yellow') +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
library(ggplot2)
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
summary(regressor)
?solve
??solve
# Simple Linear Regression
# Importing the dataset
dataset = read.csv('Salary_Data.csv')
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
#library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
# training_set = scale(training_set)
# test_set = scale(test_set)
# Fitting Simple Linear Regression to the Training set
# Salary ~ YearsExperience stand for the Salary is proportional to YearsExperience
regressor = lm(formula = Salary ~ YearsExperience,
data = training_set)
# Predicting the Test set results
y_pred = predict(regressor, newdata = test_set)
# Visualising the Training set results
library(ggplot2)
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
# Visualising the Test set results
library(ggplot2)
ggplot() +
geom_point(aes(x = test_set$YearsExperience, y = test_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Experience (Test set)') +
xlab('Years of experience') +
ylab('Salary')
?ggplot2
ggplot()
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red')
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary)
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red')
ggplot()
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red')
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red')
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red')
?lm
library(ggplot2)
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
library(help = "stats")
